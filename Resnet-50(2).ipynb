{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.applications.resnet50 import ResNet50\n",
    "from keras.preprocessing import image\n",
    "from keras.applications.resnet50 import preprocess_input, decode_predictions\n",
    "import numpy as np\n",
    "from keras import Sequential\n",
    "from keras.layers import Conv1D\n",
    "import os\n",
    "import sys\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import tensorflow\n",
    "import keras\n",
    "sys.path.append(\"..\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load images\n",
    "def load_data(data_directory):\n",
    "    directories = [d for d in os.listdir(data_directory) \n",
    "                   if os.path.isdir(os.path.join(data_directory, d))]\n",
    "    labels = []\n",
    "    images = []\n",
    "    for d in directories:\n",
    "        label_directory = os.path.join(data_directory, d)\n",
    "        file_names = [os.path.join(label_directory, f) \n",
    "                      for f in os.listdir(label_directory) \n",
    "                      if f.endswith(\".ppm\")]\n",
    "        for f in file_names:\n",
    "            images.append(cv2.imread(f))\n",
    "            labels.append(int(d))\n",
    "    return images, labels\n",
    "ROOT_PATH = \"\"\n",
    "train_data_directory = os.path.join(ROOT_PATH, \"Training\")\n",
    "test_data_directory = os.path.join(ROOT_PATH, \"Testing\")\n",
    "\n",
    "\n",
    "x_train, y_train = load_data(train_data_directory)\n",
    "x_train = np.array(x_train)\n",
    "y_train = np.array(y_train)\n",
    "\n",
    "x_test, y_test = load_data(test_data_directory)\n",
    "x_test = np.array(x_test)\n",
    "y_test = np.array(y_test)\n",
    "#Preprocess\n",
    "x_test = [cv2.resize(image, (32, 32)) for image in x_test]\n",
    "x_train = [cv2.resize(image, (32, 32)) for image in x_train]\n",
    "x_test = np.array(x_test)\n",
    "x_train = np.array(x_train)\n",
    "\n",
    "y_train = np.reshape(y_train,[y_train.shape[0],1])\n",
    "y_test = np.reshape(y_test,[y_test.shape[0],1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "from sklearn.datasets import load_files   \n",
    "from keras.utils import np_utils\n",
    "from glob import glob\n",
    "from keras import applications\n",
    "from keras.preprocessing.image import ImageDataGenerator \n",
    "from keras import optimizers\n",
    "from keras.models import Sequential,Model,load_model\n",
    "from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPool2D,GlobalAveragePooling2D\n",
    "from keras.callbacks import TensorBoard,ReduceLROnPlateau,ModelCheckpoint\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_height,img_width = 32,32 \n",
    "num_classes = 62\n",
    "#If imagenet weights are being loaded, \n",
    "#input must have a static square shape (one of (128, 128), (160, 160), (192, 192), or (224, 224))\n",
    "base_model = applications.resnet50.ResNet50(weights= None, include_top=False, input_shape= (img_height,img_width,3))\n",
    "\n",
    "def convert_to_one_hot(Y, C):\n",
    "    Y = np.eye(C)[Y.reshape(-1)].T\n",
    "    return Y\n",
    "\n",
    "y_train = convert_to_one_hot(y_train, 62).T\n",
    "y_test = convert_to_one_hot(y_test, 62).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = base_model.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = Dropout(0.7)(x)\n",
    "predictions = Dense(num_classes, activation= 'softmax')(x)\n",
    "model = Model(inputs = base_model.input, outputs = predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.optimizers import SGD, Adam\n",
    "# sgd = SGD(lr=lrate, momentum=0.9, decay=decay, nesterov=False)\n",
    "adam = Adam(lr=0.0001)\n",
    "model.compile(optimizer= adam, loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      " 768/4575 [====>.........................] - ETA: 7:57 - loss: 8.8663 - acc: 0.0286"
     ]
    }
   ],
   "source": [
    "model.fit(np.array(x_train), np.array(y_train), epochs = 100, batch_size = 64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
