{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import tensorflow\n",
    "import keras\n",
    "import keras, keras.layers as L\n",
    "sys.path.append(\"..\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load images\n",
    "def load_data(data_directory):\n",
    "    directories = [d for d in os.listdir(data_directory) \n",
    "                   if os.path.isdir(os.path.join(data_directory, d))]\n",
    "    labels = []\n",
    "    images = []\n",
    "    for d in directories:\n",
    "        label_directory = os.path.join(data_directory, d)\n",
    "        file_names = [os.path.join(label_directory, f) \n",
    "                      for f in os.listdir(label_directory) \n",
    "                      if f.endswith(\".ppm\")]\n",
    "        for f in file_names:\n",
    "            images.append(cv2.imread(f))\n",
    "            labels.append(int(d))\n",
    "    return images, labels\n",
    "ROOT_PATH = \"\"\n",
    "train_data_directory = os.path.join(ROOT_PATH, \"Training\")\n",
    "test_data_directory = os.path.join(ROOT_PATH, \"Testing\")\n",
    "\n",
    "\n",
    "x_train, y_train = load_data(train_data_directory)\n",
    "x_train = np.array(x_train)\n",
    "y_train = np.array(y_train)\n",
    "\n",
    "x_test, y_test = load_data(test_data_directory)\n",
    "x_test = np.array(x_test)\n",
    "y_test = np.array(y_test)\n",
    "#Preprocess\n",
    "x_test = [cv2.resize(image, (28, 28)) for image in x_test]\n",
    "x_train = [cv2.resize(image, (28, 28)) for image in x_train]\n",
    "x_test = np.array(x_test)\n",
    "x_train = np.array(x_train)\n",
    "\n",
    "y_train = np.reshape(y_train,[y_train.shape[0],1])\n",
    "y_test = np.reshape(y_test,[y_test.shape[0],1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert class labels to one-hot encoded, should have shape (?, NUM_CLASSES)\n",
    "y_train2 = keras.utils.to_categorical(y_train)\n",
    "y_test2 = keras.utils.to_categorical(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_deep_autoencoder(img_shape,code_size=32):\n",
    "    \"\"\"PCA's deeper brother. See instructions above\"\"\"\n",
    "    H,W,C = img_shape\n",
    "    NFILTERS=16\n",
    "    N1=256\n",
    "\n",
    "    encoder = keras.models.Sequential()\n",
    "    encoder.add(L.InputLayer(img_shape))\n",
    "    encoder.add(L.normalization.BatchNormalization(axis=1))\n",
    "    \n",
    "    #Convolutions\n",
    "    encoder.add(L.Conv2D(filters=NFILTERS*2,kernel_size=3,padding=\"same\"))\n",
    "    encoder.add(L.advanced_activations.LeakyReLU())\n",
    "    encoder.add(L.Conv2D(filters=NFILTERS,kernel_size=3,padding=\"same\"))\n",
    "    encoder.add(L.advanced_activations.LeakyReLU())\n",
    "    encoder.add(L.MaxPooling2D())\n",
    "\n",
    "    \n",
    "    encoder.add(L.Flatten()) \n",
    "    \n",
    "    encoder.add(L.Dense(N1))\n",
    "    encoder.add(L.advanced_activations.LeakyReLU())\n",
    "    encoder.add(L.normalization.BatchNormalization())\n",
    "    encoder.add(L.Dense(N1))\n",
    "    encoder.add(L.advanced_activations.LeakyReLU())\n",
    "    encoder.add(L.normalization.BatchNormalization())    \n",
    "    \n",
    "    encoder.add(L.Dense(code_size))\n",
    "   \n",
    "    \n",
    "    decoder = keras.models.Sequential()\n",
    "    decoder.add(L.InputLayer((code_size,)))\n",
    "    decoder.add(L.normalization.BatchNormalization())\n",
    "    \n",
    "    decoder.add(L.Dense(N1))\n",
    "    decoder.add(L.advanced_activations.LeakyReLU())\n",
    "    decoder.add(L.normalization.BatchNormalization())\n",
    "    decoder.add(L.Dense(N1))\n",
    "    decoder.add(L.advanced_activations.LeakyReLU())\n",
    "    decoder.add(L.normalization.BatchNormalization())   \n",
    "    \n",
    "    \n",
    "    decoder.add(L.Dense(np.prod(img_shape)//4))\n",
    "    decoder.add(L.advanced_activations.LeakyReLU()) \n",
    "    decoder.add(L.normalization.BatchNormalization()) \n",
    "    decoder.add(L.Reshape((H//2,W//2,C)))   \n",
    "    decoder.add(L.UpSampling2D())\n",
    "\n",
    "    decoder.add(L.Deconv2D(filters=NFILTERS,kernel_size=3,padding=\"same\"))\n",
    "    decoder.add(L.advanced_activations.LeakyReLU())\n",
    "    decoder.add(L.Deconv2D(filters=NFILTERS*2,kernel_size=3,padding=\"same\")) \n",
    "    \n",
    "    encoder.add(L.advanced_activations.LeakyReLU())\n",
    "    decoder.add(L.Deconv2D(filters=3,kernel_size=3,padding=\"same\"))\n",
    "\n",
    "    \n",
    "    return encoder,decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder,decoder = build_deep_autoencoder(img_shape,code_size=32)\n",
    "\n",
    "inp = L.Input(img_shape)\n",
    "code = encoder(inp)\n",
    "reconstruction = decoder(code)\n",
    "\n",
    "autoencoder = keras.models.Model(inp,reconstruction)\n",
    "\n",
    "encoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder,decoder = build_deep_autoencoder(img_shape,code_size=512)\n",
    "assert encoder.output_shape[1:]==(512,), \"encoder must output a code of required size\"\n",
    "\n",
    "inp = L.Input(img_shape)\n",
    "code = encoder(inp)\n",
    "reconstruction = decoder(code)\n",
    "\n",
    "autoencoder = keras.models.Model(inp,reconstruction)\n",
    "autoencoder.compile('adamax','mse')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(50):\n",
    "    print(\"Epoch %i/50, Generating corrupted samples...\"%i)\n",
    "    X_train_noise = apply_gaussian_noise(x_train)\n",
    "    X_test_noise = apply_gaussian_noise(x_test)\n",
    "    \n",
    "    autoencoder.fit(x=X_train_noise,y=x_train,epochs=1,\n",
    "                    validation_data=[X_test_noise,x_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize(img,encoder,decoder):\n",
    "    \"\"\"Draws original, encoded and decoded images\"\"\"\n",
    "    code = encoder.predict(img[None])[0]\n",
    "    reco = decoder.predict(code[None])[0]\n",
    "\n",
    "    plt.subplot(1,3,1)\n",
    "    plt.title(\"Original\")\n",
    "    plt.imshow(img)\n",
    "\n",
    "    plt.subplot(1,3,2)\n",
    "    plt.title(\"Code\")\n",
    "    plt.imshow(code.reshape([code.shape[-1]//2,-1]))\n",
    "\n",
    "    plt.subplot(1,3,3)\n",
    "    plt.title(\"Reconstructed\")\n",
    "    plt.imshow(reco.clip(0,1))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "denoising_mse = autoencoder.evaluate(apply_gaussian_noise(X_test),X_test,verbose=0)\n",
    "\n",
    "print(\"Final MSE:\", denoising_mse)\n",
    "for i in range(5):\n",
    "    img = X_test[i]\n",
    "    visualize(img,encoder,decoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder.save(\"./encoder.h5\")\n",
    "decoder.save(\"./decoder.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
