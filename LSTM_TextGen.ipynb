{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import keras\n",
    "from keras.callbacks import LambdaCallback\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Conv1D\n",
    "from keras.layers import LSTM, Activation \n",
    "from keras.optimizers import RMSprop\n",
    "from keras.utils.data_utils import get_file\n",
    "import numpy as np\n",
    "import random\n",
    "import sys\n",
    "import io"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total chars: 56\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "start_token = \" \"\n",
    "\n",
    "with open(\"names.txt\") as f:\n",
    "    names = f.read()[:-1].split('\\n')\n",
    "    names = [start_token+name for name in names]\n",
    "\n",
    "text = '\\n'.join(names)\n",
    "\n",
    "chars = sorted(list(set(text)))\n",
    "print('total chars: {}'.format(len(chars)))\n",
    "char_indices = dict((c, i) for i, c in enumerate(chars))\n",
    "indices_char = dict((i, c) for i, c in enumerate(chars))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of sequences: 21268\n",
      "First 10 sequences and next chars:\n",
      "[ Abagael\n",
      " ]:[A]\n",
      "[agael\n",
      " Aba]:[g]\n",
      "[el\n",
      " Abagai]:[l]\n",
      "[ Abagail\n",
      " ]:[A]\n",
      "[agail\n",
      " Abb]:[e]\n",
      "[il\n",
      " Abbe\n",
      " ]:[A]\n",
      "[ Abbe\n",
      " Abb]:[e]\n",
      "[be\n",
      " Abbey\n",
      "]:[ ]\n",
      "[ Abbey\n",
      " Ab]:[b]\n",
      "[bey\n",
      " Abbi\n",
      "]:[ ]\n"
     ]
    }
   ],
   "source": [
    "maxlen = 10\n",
    "step = 3\n",
    "\n",
    "sentences = []\n",
    "next_chars = []\n",
    "for i in range(0, len(text) - maxlen, step):\n",
    "    sentences.append(text[i: i + maxlen])\n",
    "    next_chars.append(text[i + maxlen])\n",
    "print('Number of sequences:', len(sentences))\n",
    "print('First 10 sequences and next chars:')\n",
    "for i in range(10):\n",
    "    print('[{}]:[{}]'.format(sentences[i], next_chars[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.zeros((len(sentences), maxlen, len(chars)), dtype=np.bool)\n",
    "y = np.zeros((len(sentences), len(chars)), dtype=np.bool)\n",
    "for i, sentence in enumerate(sentences):\n",
    "    for t, char in enumerate(sentence):\n",
    "        X[i, t, char_indices[char]] = 1\n",
    "    y[i, char_indices[next_chars[i]]] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_17 (LSTM)               (None, 256)               320512    \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 56)                14392     \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 56)                0         \n",
      "=================================================================\n",
      "Total params: 334,904\n",
      "Trainable params: 334,904\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "nb_units = 256\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "# Recurrent layers supported: SimpleRNN, LSTM, GRU:\n",
    "model.add(LSTM(nb_units, input_shape=(maxlen, len(chars))))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "# To stack multiple RNN layers, all RNN layers except the last one need\n",
    "# to have \"return_sequences=True\".  An example of using two RNN layers:\n",
    "#model.add(SimpleRNN(16,\n",
    "#                    input_shape=(maxlen, len(chars)),\n",
    "#                    return_sequences=True))\n",
    "#model.add(SimpleRNN(32))\n",
    "\n",
    "model.add(Dense(units=len(chars)))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "optimizer = RMSprop(lr=0.01)\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=optimizer)\n",
    "\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "21268/21268 [==============================] - 15s 717us/step - loss: 3.6283\n",
      "\n",
      "----- Generating with diversity 0.2 seed: \"tor\n",
      " Nev\n",
      " \"\n",
      "tor\n",
      " Nev\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "----- Generating with diversity 0.5 seed: \"tor\n",
      " Nev\n",
      " \"\n",
      "tor\n",
      " Nev\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "u\n",
      " T\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "S\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "l\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "l\n",
      "\n",
      "b\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "n\n",
      "\n",
      "----- Generating with diversity 1.0 seed: \"tor\n",
      " Nev\n",
      " \"\n",
      "tor\n",
      " Nev\n",
      " \n",
      "\n",
      "\n",
      "r\n",
      "\n",
      "T\n",
      "l\n",
      " A\n",
      "\n",
      "\n",
      "l\n",
      " \n",
      "el\n",
      "n\n",
      "a\n",
      "\n",
      "pZ\n",
      "\n",
      "e\n",
      " l\n",
      "bnnl \n",
      "\n",
      "oe\n",
      "\n",
      "a\n",
      "l\n",
      "t\n",
      "\n",
      "n\n",
      "dbtb\n",
      "\n",
      "B\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "lald\n",
      "\n",
      "Ug\n",
      "\n",
      "Db\n",
      "bl\n",
      "\n",
      "b\n",
      "\n",
      "i\n",
      "\n",
      "b\n",
      "a\n",
      "a\n",
      "\n",
      "l\n",
      "----- Generating with diversity 1.2 seed: \"tor\n",
      " Nev\n",
      " \"\n",
      "tor\n",
      " Nev\n",
      " gn\n",
      "l\n",
      "\n",
      "notns\n",
      " Kl J\n",
      "l\n",
      "ylolll\n",
      " \n",
      "ll\n",
      "sh\n",
      "\n",
      "Slod\n",
      "ld\n",
      "\n",
      "b\n",
      "yn\n",
      "llAtao\n",
      "\n",
      "z\n",
      "ly\n",
      "nl\n",
      "\n",
      "\n",
      "\n",
      "li\n",
      "\n",
      "\n",
      "ay\n",
      " Ryb\n",
      " \n",
      " \n",
      "lonlv\n",
      "T\n",
      "aAlul\n",
      "\n",
      "\n",
      "\n",
      "Epoch 2/10\n",
      "21268/21268 [==============================] - 15s 720us/step - loss: 2.0131\n",
      "\n",
      "----- Generating with diversity 0.2 seed: \" Britta\n",
      " B\"\n",
      " Britta\n",
      " Brerie\n",
      " Beresie\n",
      " Beere\n",
      " Beeee\n",
      " Beeee\n",
      " Beeee\n",
      " Beeee\n",
      " Beeeee\n",
      " Beeee\n",
      " Beeeee\n",
      " Beeeee\n",
      " Beeeee\n",
      " Beeeee\n",
      " Be\n",
      "----- Generating with diversity 0.5 seed: \" Britta\n",
      " B\"\n",
      " Britta\n",
      " Beyite\n",
      " Beeel\n",
      " Beeeeed\n",
      " Beeeele\n",
      " Beeemeene\n",
      " Jeeeee\n",
      " Jeee\n",
      " Jeeee\n",
      " Jeeee\n",
      " Jeeeeene\n",
      " Jeeeee\n",
      " Jeeefe\n",
      " Jee\n",
      "----- Generating with diversity 1.0 seed: \" Britta\n",
      " B\"\n",
      " Britta\n",
      " Brisy\n",
      " Bdeld\n",
      " Geeerene\n",
      " Jeeerier\n",
      " Jeleyeele\n",
      " GeyleetdeenaPlene\n",
      " Jhesie\n",
      " Jeeiboereeeceren\n",
      " Jeelesseeda\n",
      "----- Generating with diversity 1.2 seed: \" Britta\n",
      " B\"\n",
      " Britta\n",
      " Bbizenleyeci\n",
      " Voly\n",
      " HegsDreee\n",
      " Jabepede\n",
      " Jeeemtideee\n",
      " Cerse\n",
      " Fyseredaferesl\n",
      " Vaceee\n",
      " Hacse\n",
      " Secherole\n",
      "\n",
      "\n",
      "Epoch 3/10\n",
      "21268/21268 [==============================] - 16s 748us/step - loss: 1.4539\n",
      "\n",
      "----- Generating with diversity 0.2 seed: \"ay\n",
      " Cooper\"\n",
      "ay\n",
      " Cooperie\n",
      " Corierie\n",
      " Corie\n",
      " Cororie\n",
      " Corrie\n",
      " Corrie\n",
      " Corrisa\n",
      " Corristona\n",
      " Mistie\n",
      " Mistie\n",
      " Mistie\n",
      " Mitiette\n",
      "\n",
      "----- Generating with diversity 0.5 seed: \"ay\n",
      " Cooper\"\n",
      "ay\n",
      " Cooperine\n",
      " Coriste\n",
      " Corisie\n",
      " Corissie\n",
      " Coristey\n",
      " Coriy\n",
      " Coriette\n",
      " Corinean\n",
      " Coriany\n",
      " Coria\n",
      " Coroy\n",
      " Cororey\n",
      "----- Generating with diversity 1.0 seed: \"ay\n",
      " Cooper\"\n",
      "ay\n",
      " Cooperoma\n",
      " Ponris\n",
      " Popisa\n",
      " Poniy\n",
      " Poonay\n",
      " Polonione\n",
      " Csanopsl\n",
      " Caniesa\n",
      " Caioie\n",
      " Cacay\n",
      " Casharle\n",
      " Cashyrana\n",
      "----- Generating with diversity 1.2 seed: \"ay\n",
      " Cooper\"\n",
      "ay\n",
      " Cooperta\n",
      " Coranerbiry\n",
      " Harieryie\n",
      " Giace\n",
      " Jiqiiic\n",
      " Jiceince\n",
      " Jicelalin\n",
      " Juanillaue\n",
      " lionidig\n",
      " Finiollisonen\n",
      "\n",
      "\n",
      "Epoch 4/10\n",
      "21268/21268 [==============================] - 16s 750us/step - loss: 1.2613\n",
      "\n",
      "----- Generating with diversity 0.2 seed: \"h\n",
      " Walt\n",
      " W\"\n",
      "h\n",
      " Walt\n",
      " Walle\n",
      " Wallin\n",
      " Wallie\n",
      " Walli\n",
      " Wallin\n",
      " Wallie\n",
      " Walli\n",
      " Wallie\n",
      " Wallin\n",
      " Wallie\n",
      " Walla\n",
      " Walle\n",
      " Wallin\n",
      " Wa\n",
      "----- Generating with diversity 0.5 seed: \"h\n",
      " Walt\n",
      " W\"\n",
      "h\n",
      " Walt\n",
      " Walle\n",
      " Wallie\n",
      " Walli\n",
      " Walla\n",
      " Wallie\n",
      " Wallia\n",
      " Walfa\n",
      " Walli\n",
      " Walla\n",
      " Walse\n",
      " Walle\n",
      " Wallie\n",
      " Walvie\n",
      " Wally\n",
      "----- Generating with diversity 1.0 seed: \"h\n",
      " Walt\n",
      " W\"\n",
      "h\n",
      " Walt\n",
      " Walvaa\n",
      " Walyn\n",
      " Wals\n",
      " Waitt\n",
      " Wal\n",
      " Wastn\n",
      " Wals\n",
      " Walt\n",
      " Walshoro\n",
      " Wallaa\n",
      " Waland\n",
      " Walan\n",
      " Walpa\n",
      " Walle\n",
      " Wa\n",
      "----- Generating with diversity 1.2 seed: \"h\n",
      " Walt\n",
      " W\"\n",
      "h\n",
      " Walt\n",
      " Wales\n",
      " Waler\n",
      " Wayly\n",
      " Wayle\n",
      " Walil\n",
      " Wallina\n",
      " Walmart\n",
      " Wanema\n",
      " Wancon\n",
      " Warria\n",
      " Warnela\n",
      " Warsep\n",
      " Ware\n",
      " W\n",
      "\n",
      "\n",
      "Epoch 5/10\n",
      "21268/21268 [==============================] - 16s 748us/step - loss: 1.1323\n",
      "\n",
      "----- Generating with diversity 0.2 seed: \"elle\n",
      " Gay\n",
      "\"\n",
      "elle\n",
      " Gay\n",
      " Gayla\n",
      " Gayley\n",
      " Gaylie\n",
      " Gaylie\n",
      " Gaylie\n",
      " Gaylie\n",
      " Gaylie\n",
      " Gayly\n",
      " Gayley\n",
      " Gaylie\n",
      " Gayly\n",
      " Gay\n",
      " Gayle\n",
      " Ga\n",
      "----- Generating with diversity 0.5 seed: \"elle\n",
      " Gay\n",
      "\"\n",
      "elle\n",
      " Gay\n",
      " Gayle\n",
      " Gay\n",
      " Gay\n",
      " Gayle\n",
      " Gayley\n",
      " Gaylie\n",
      " Gaylie\n",
      " Gayly\n",
      " Gay\n",
      " Gayla\n",
      " Gaylie\n",
      " Gaylie\n",
      " Gayaria\n",
      " Gayrici\n",
      "----- Generating with diversity 1.0 seed: \"elle\n",
      " Gay\n",
      "\"\n",
      "elle\n",
      " Gay\n",
      " Gaiehien\n",
      " Gari\n",
      " Garis\n",
      " Gariacie\n",
      " Garide\n",
      " Gariy\n",
      " Garra\n",
      " Gartey\n",
      " Garihane\n",
      " Gariha\n",
      " Gariparin\n",
      " Mricind\n",
      "----- Generating with diversity 1.2 seed: \"elle\n",
      " Gay\n",
      "\"\n",
      "elle\n",
      " Gay\n",
      " Gay\n",
      " Gaiv\n",
      " naffuentia\n",
      " Cuecr\n",
      " Cewfraton\n",
      " Lmytte\n",
      " Lyak\n",
      " Lyae\n",
      " Lyah\n",
      " Lyan\n",
      " Lyian\n",
      " Lyemyay\n",
      " Lyyba\n",
      " Lyl\n",
      "\n",
      "\n",
      "Epoch 6/10\n",
      "21268/21268 [==============================] - 16s 733us/step - loss: 1.0156\n",
      "\n",
      "----- Generating with diversity 0.2 seed: \"agdalen\n",
      " M\"\n",
      "agdalen\n",
      " Maggeline\n",
      " Meline\n",
      " Meline\n",
      " Meline\n",
      " Meline\n",
      " Melis\n",
      " Mellis\n",
      " Mellissa\n",
      " Mellie\n",
      " Melisse\n",
      " Mellie\n",
      " Mellie\n",
      " \n",
      "----- Generating with diversity 0.5 seed: \"agdalen\n",
      " M\"\n",
      "agdalen\n",
      " Magdae\n",
      " Margeta\n",
      " Margie\n",
      " Margine\n",
      " Margerer\n",
      " Margena\n",
      " Margena\n",
      " Margena\n",
      " Marge\n",
      " Marga\n",
      " Margie\n",
      " Margie\n",
      " \n",
      "----- Generating with diversity 1.0 seed: \"agdalen\n",
      " M\"\n",
      "agdalen\n",
      " Maguena\n",
      " Magexeda\n",
      " Magrea\n",
      " Margonella\n",
      " Moniil\n",
      " Morniens\n",
      " Mory\n",
      " Aobey\n",
      " Abayl\n",
      " Aby\n",
      " Aygery\n",
      " Ayere\n",
      " Ayen\n",
      "----- Generating with diversity 1.2 seed: \"agdalen\n",
      " M\"\n",
      "agdalen\n",
      " Maideen\n",
      " Midolea\n",
      " Morjine\n",
      " Morulotna\n",
      " Sky\n",
      " Sytey\n",
      " Sckveyla\n",
      " Ribeetan\n",
      " Reberus\n",
      " Rezria\n",
      " Reyney\n",
      " Reyla\n",
      "\n",
      "\n",
      "\n",
      "Epoch 7/10\n",
      "21268/21268 [==============================] - 16s 741us/step - loss: 0.8973\n",
      "\n",
      "----- Generating with diversity 0.2 seed: \"lasdair\n",
      " A\"\n",
      "lasdair\n",
      " Alasa\n",
      " Alassa\n",
      " Alassi\n",
      " Alasia\n",
      " Alasia\n",
      " Alasia\n",
      " Alasia\n",
      " Ala\n",
      " Alia\n",
      " Alisia\n",
      " Alitia\n",
      " Alitta\n",
      " Alitta\n",
      " Ali\n",
      "----- Generating with diversity 0.5 seed: \"lasdair\n",
      " A\"\n",
      "lasdair\n",
      " Alexaa\n",
      " Alexa\n",
      " Alexa\n",
      " Alexa\n",
      " Alixa\n",
      " Alia\n",
      " Alisie\n",
      " Alisie\n",
      " Alisio\n",
      " Alitie\n",
      " Alilie\n",
      " Alista\n",
      " Alitia\n",
      " Ali\n",
      "----- Generating with diversity 1.0 seed: \"lasdair\n",
      " A\"\n",
      "lasdair\n",
      " Alexa\n",
      " Alexael\n",
      " Alie\n",
      " Alis\n",
      " Alislo\n",
      " Alittare\n",
      " Alotta\n",
      " Allie\n",
      " All\n",
      " xin\n",
      " Alia\n",
      " Alia\n",
      " Alimit\n",
      " Alitty\n",
      " Al\n",
      "----- Generating with diversity 1.2 seed: \"lasdair\n",
      " A\"\n",
      "lasdair\n",
      " Alaraus\n",
      " Alia\n",
      " Alisia\n",
      " Aliusa\n",
      " Ali\n",
      " Aliaeie\n",
      " Aitoali\n",
      " Art\n",
      " Qiuferitta\n",
      " Antteas\n",
      " Anteli\n",
      " Antine\n",
      " Antru\n",
      "\n",
      "\n",
      "Epoch 8/10\n",
      "21268/21268 [==============================] - 16s 763us/step - loss: 0.7837\n",
      "\n",
      "----- Generating with diversity 0.2 seed: \" Ladonna\n",
      " \"\n",
      " Ladonna\n",
      " Ladora\n",
      " Laddy\n",
      " Laddin\n",
      " Laddy\n",
      " Ladda\n",
      " Laddie\n",
      " Laddy\n",
      " Ladda\n",
      " Laddie\n",
      " Laddy\n",
      " Laddie\n",
      " Laddy\n",
      " Ladda\n",
      " Ladd\n",
      "----- Generating with diversity 0.5 seed: \" Ladonna\n",
      " \"\n",
      " Ladonna\n",
      " Lard\n",
      " Lardie\n",
      " Lardy\n",
      " Lardan\n",
      " Lardy\n",
      " Lardina\n",
      " Larda\n",
      " Lardene\n",
      " Lardy\n",
      " Lardie\n",
      " Lardy\n",
      " Lardy\n",
      " Larrie\n",
      " La\n",
      "----- Generating with diversity 1.0 seed: \" Ladonna\n",
      " \"\n",
      " Ladonna\n",
      " Lador\n",
      " Laddyn\n",
      " Laddy\n",
      " Ladien\n",
      " Ladno\n",
      " Lade\n",
      " Laddanda\n",
      " Ladily\n",
      " Laden\n",
      " Laddy\n",
      " Ladie\n",
      " Ladi\n",
      " Ladon\n",
      " Laddi\n",
      "----- Generating with diversity 1.2 seed: \" Ladonna\n",
      " \"\n",
      " Ladonna\n",
      " Laisie\n",
      " Lanlia\n",
      " Lanni\n",
      " Lann\n",
      " Lanni-\n",
      " Lancy\n",
      " Landa\n",
      " Landie\n",
      " Landy\n",
      " Lanna\n",
      " Land\n",
      " Laniti\n",
      " Landy\n",
      " Ladeyl\n",
      "\n",
      "\n",
      "Epoch 9/10\n",
      "21268/21268 [==============================] - 15s 720us/step - loss: 0.6601\n",
      "\n",
      "----- Generating with diversity 0.2 seed: \"y\n",
      " Sibeal\n",
      "\"\n",
      "y\n",
      " Sibeal\n",
      " Sibella\n",
      " Sibella\n",
      " Sidella\n",
      " Sidelle\n",
      " Sidella\n",
      " Sidelle\n",
      " Sidella\n",
      " Sidella\n",
      " Sidella\n",
      " Sidella\n",
      " Sidella\n",
      " \n",
      "----- Generating with diversity 0.5 seed: \"y\n",
      " Sibeal\n",
      "\"\n",
      "y\n",
      " Sibeal\n",
      " Sibella\n",
      " Sidelle\n",
      " Sidella\n",
      " Sidelle\n",
      " Sidelle\n",
      " Sidella\n",
      " Sidella\n",
      " Sidelle\n",
      " Sidelle\n",
      " Sidella\n",
      " Sidella\n",
      " \n",
      "----- Generating with diversity 1.0 seed: \"y\n",
      " Sibeal\n",
      "\"\n",
      "y\n",
      " Sibeal\n",
      " Sidetta\n",
      " Sidulla\n",
      " Sily\n",
      " Silda\n",
      " Sildaghand\n",
      " ad\n",
      " Eadia\n",
      " Eandie\n",
      " Eandy\n",
      " Eanora\n",
      " Eamora\n",
      " Eamnka\n",
      " Eami\n",
      " \n",
      "----- Generating with diversity 1.2 seed: \"y\n",
      " Sibeal\n",
      "\"\n",
      "y\n",
      " Sibeal\n",
      " Sibey\n",
      " Sid\n",
      " Sidb\n",
      " Siddy\n",
      " Sid\n",
      " Siddey\n",
      " Sidzedin\n",
      " oide\n",
      " cida\n",
      " Nidde\n",
      " Nidis\n",
      " Niltir\n",
      " Ninisdilo\n",
      " tosty\n",
      "\n",
      "\n",
      "\n",
      "Epoch 10/10\n",
      "21268/21268 [==============================] - 17s 789us/step - loss: 0.5612\n",
      "\n",
      "----- Generating with diversity 0.2 seed: \"Harriot\n",
      " H\"\n",
      "Harriot\n",
      " Harro\n",
      " Harra\n",
      " Harra\n",
      " Harora\n",
      " Harora\n",
      " Harora\n",
      " Harora\n",
      " Harora\n",
      " Harora\n",
      " Harora\n",
      " Harora\n",
      " Harora\n",
      " Harora\n",
      " \n",
      "----- Generating with diversity 0.5 seed: \"Harriot\n",
      " H\"\n",
      "Harriot\n",
      " Harro\n",
      " Harra\n",
      " Harshe\n",
      " Hasson\n",
      " Haston\n",
      " Hava\n",
      " Havela\n",
      " Havina\n",
      " Havinda\n",
      " Havion\n",
      " Havind\n",
      " Havind\n",
      " Havin\n",
      " H\n",
      "----- Generating with diversity 1.0 seed: \"Harriot\n",
      " H\"\n",
      "Harriot\n",
      " Harrold\n",
      " Harollon\n",
      " Harold\n",
      " Harrald\n",
      " Harrand\n",
      " Harna\n",
      " Harnoe\n",
      " Haron\n",
      " Harole\n",
      " Harlodo\n",
      " Harlous\n",
      " Harlone\n",
      "\n",
      "----- Generating with diversity 1.2 seed: \"Harriot\n",
      " H\"\n",
      "Harriot\n",
      " Harro\n",
      " Harra\n",
      " Harlarie\n",
      " Herja\n",
      " Herloin\n",
      " Herlord\n",
      " Herloe\n",
      " Hersell\n",
      " Hestille\n",
      " colly\n",
      " Loley\n",
      " Lolenna\n",
      " Lo\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0xb3856bad0>"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def sample(preds, temperature=1.0):\n",
    "    # helper function to sample an index from a probability array\n",
    "    preds = np.asarray(preds).astype('float64')\n",
    "    preds = np.log(preds) / temperature\n",
    "    exp_preds = np.exp(preds)\n",
    "    preds = exp_preds / np.sum(exp_preds)\n",
    "    probas = np.random.multinomial(1, preds, 1)\n",
    "    return np.argmax(probas)\n",
    "\n",
    "class SampleResult(keras.callbacks.Callback):\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "\n",
    "        start_index = random.randint(0, len(text) - maxlen - 1)\n",
    "\n",
    "        for diversity in [0.2, 0.5, 1.0, 1.2]:\n",
    "            generated = ''\n",
    "            sentence = text[start_index: start_index + maxlen]\n",
    "            generated += sentence\n",
    "            print()\n",
    "            print('----- Generating with diversity',\n",
    "                  diversity, 'seed: \"' + sentence + '\"')\n",
    "            sys.stdout.write(generated)\n",
    "\n",
    "            for i in range(100):\n",
    "                X = np.zeros((1, maxlen, len(chars)))\n",
    "                for t, char in enumerate(sentence):\n",
    "                    X[0, t, char_indices[char]] = 1.\n",
    "\n",
    "                preds = self.model.predict(X, verbose=0)[0]\n",
    "                next_index = sample(preds, diversity)\n",
    "                next_char = indices_char[next_index]\n",
    "\n",
    "                generated += next_char\n",
    "                sentence = sentence[1:] + next_char\n",
    "\n",
    "                sys.stdout.write(next_char)\n",
    "                sys.stdout.flush()\n",
    "        print('\\n\\n')\n",
    "        \n",
    "sample_callback = SampleResult()\n",
    "model.fit(X, y,\n",
    "          batch_size=128,\n",
    "          epochs=10,\n",
    "          callbacks=[sample_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
