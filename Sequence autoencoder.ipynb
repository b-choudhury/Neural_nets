{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "run onehotencode.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import numpy as np\n",
    "import tensorflow\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "import keras, keras.layers as L\n",
    "sys.path.append(\"..\")\n",
    "from keras.models import load_model\n",
    "from keras.layers import Input, Dense, Conv2D, LSTM, MaxPooling2D, UpSampling2D, BatchNormalization, Activation, Bidirectional\n",
    "from keras.models import Model\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from keras.optimizers import Adam\n",
    "import os\n",
    "import pickle\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(120, 56)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xtrain=np.array(xtrain)\n",
    "img_shape=xtrain[0].shape\n",
    "img_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras_self_attention import SeqSelfAttention\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_pca_autoencoder(img_shape,code_size=32):\n",
    "    \"\"\"\n",
    "    Here we define a simple linear autoencoder as described above.\n",
    "    We also flatten and un-flatten data to be compatible with image shapes\n",
    "    \"\"\"\n",
    "    \n",
    "    encoder = keras.models.Sequential()\n",
    "    encoder.add(L.InputLayer(img_shape))\n",
    "    encoder.add(L.Conv1D(filters=100, kernel_size=4, padding='same', activation='relu'))\n",
    "    encoder.add(L.Bidirectional(LSTM(100,return_sequences=True)))\n",
    "    encoder.add(L.Conv1D(filters=100, kernel_size=4, padding='same', activation='relu'))\n",
    "    encoder.add(L.Bidirectional(LSTM(100,return_sequences=True)))\n",
    "    encoder.add(L.Conv1D(filters=100, kernel_size=4, padding='same', activation='relu'))\n",
    "    encoder.add(L.Bidirectional(LSTM(100,return_sequences=True)))\n",
    "    encoder.add(L.Conv1D(filters=100, kernel_size=4, padding='same', activation='relu'))\n",
    "    encoder.add(L.Bidirectional(LSTM(100,return_sequences=True)))\n",
    "    encoder.add(L.Conv1D(filters=100, kernel_size=4, padding='same', activation='relu'))\n",
    "    encoder.add(L.Bidirectional(LSTM(100,return_sequences=True)))\n",
    "    encoder.add(SeqSelfAttention(attention_activation='tanh'))\n",
    "    encoder.add(SeqSelfAttention(attention_activation='tanh'))\n",
    "    encoder.add(SeqSelfAttention(attention_activation='tanh'))\n",
    "    encoder.add(SeqSelfAttention(attention_activation='tanh'))\n",
    "    encoder.add(L.Flatten())\n",
    "    encoder.add(L.Dense(code_size))\n",
    "    \n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    decoder = keras.models.Sequential()\n",
    "    decoder.add(L.InputLayer((code_size,)))\n",
    "    decoder.add(L.Dense(256))\n",
    "    decoder.add(L.Dense(np.prod(img_shape)))#actual decoder, height*width*3 units\n",
    "    decoder.add(L.Reshape(img_shape))#un-flatten\n",
    "    decoder.add(SeqSelfAttention(attention_activation='tanh'))\n",
    "    decoder.add(SeqSelfAttention(attention_activation='tanh'))\n",
    "    decoder.add(SeqSelfAttention(attention_activation='tanh'))\n",
    "    decoder.add(SeqSelfAttention(attention_activation='tanh'))\n",
    "    return encoder,decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder,decoder = build_pca_autoencoder(img_shape,code_size=32)\n",
    "\n",
    "inp = L.Input(img_shape)\n",
    "code = encoder(inp)\n",
    "reconstruction = decoder(code)\n",
    "\n",
    "autoencoder = keras.models.Model(inp,reconstruction)\n",
    "autoencoder.compile('adamax','mse')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /opt/anaconda2/lib/python2.7/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "WARNING:tensorflow:From /opt/anaconda2/lib/python2.7/site-packages/tensorflow/python/ops/math_grad.py:102: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Deprecated in favor of operator or tf.math.divide.\n",
      "Epoch 1/32\n",
      "23/23 [==============================] - 11s 476ms/step - loss: 0.0056\n",
      "Epoch 2/32\n",
      "23/23 [==============================] - 2s 101ms/step - loss: 0.0055\n",
      "Epoch 3/32\n",
      "23/23 [==============================] - 3s 117ms/step - loss: 0.0054\n",
      "Epoch 4/32\n",
      "23/23 [==============================] - 3s 118ms/step - loss: 0.0098\n",
      "Epoch 5/32\n",
      "23/23 [==============================] - 2s 91ms/step - loss: 0.0054\n",
      "Epoch 6/32\n",
      "23/23 [==============================] - 2s 88ms/step - loss: 0.0055\n",
      "Epoch 7/32\n",
      "23/23 [==============================] - 2s 91ms/step - loss: 0.0055\n",
      "Epoch 8/32\n",
      "23/23 [==============================] - 2s 106ms/step - loss: 0.0055\n",
      "Epoch 9/32\n",
      "23/23 [==============================] - 2s 88ms/step - loss: 0.0055\n",
      "Epoch 10/32\n",
      "23/23 [==============================] - 4s 171ms/step - loss: 0.0055\n",
      "Epoch 11/32\n",
      "23/23 [==============================] - 3s 146ms/step - loss: 0.0055\n",
      "Epoch 12/32\n",
      "23/23 [==============================] - 2s 94ms/step - loss: 0.0055\n",
      "Epoch 13/32\n",
      "23/23 [==============================] - 2s 95ms/step - loss: 0.0055\n",
      "Epoch 14/32\n",
      "23/23 [==============================] - 2s 94ms/step - loss: 0.0054\n",
      "Epoch 15/32\n",
      "23/23 [==============================] - 2s 85ms/step - loss: 0.0054\n",
      "Epoch 16/32\n",
      "23/23 [==============================] - 2s 96ms/step - loss: 0.0054\n",
      "Epoch 17/32\n",
      "23/23 [==============================] - 2s 92ms/step - loss: 0.0054\n",
      "Epoch 18/32\n",
      "23/23 [==============================] - 2s 100ms/step - loss: 0.0054\n",
      "Epoch 19/32\n",
      "23/23 [==============================] - 2s 92ms/step - loss: 0.0054\n",
      "Epoch 20/32\n",
      "23/23 [==============================] - 2s 93ms/step - loss: 0.0053\n",
      "Epoch 21/32\n",
      "23/23 [==============================] - 2s 95ms/step - loss: 0.0053\n",
      "Epoch 22/32\n",
      "23/23 [==============================] - 2s 85ms/step - loss: 0.0053\n",
      "Epoch 23/32\n",
      "23/23 [==============================] - 2s 85ms/step - loss: 0.0053\n",
      "Epoch 24/32\n",
      "23/23 [==============================] - 3s 111ms/step - loss: 0.0053\n",
      "Epoch 25/32\n",
      "23/23 [==============================] - 2s 89ms/step - loss: 0.0053\n",
      "Epoch 26/32\n",
      "23/23 [==============================] - 2s 95ms/step - loss: 0.0053\n",
      "Epoch 27/32\n",
      "23/23 [==============================] - 2s 82ms/step - loss: 0.0053\n",
      "Epoch 28/32\n",
      "23/23 [==============================] - 2s 79ms/step - loss: 0.0053\n",
      "Epoch 29/32\n",
      "23/23 [==============================] - 2s 89ms/step - loss: 0.0053\n",
      "Epoch 30/32\n",
      "23/23 [==============================] - 2s 97ms/step - loss: 0.0053\n",
      "Epoch 31/32\n",
      "23/23 [==============================] - 2s 98ms/step - loss: 0.0053\n",
      "Epoch 32/32\n",
      "23/23 [==============================] - 2s 91ms/step - loss: 0.0053\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x1c34a53690>"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "autoencoder.fit(x=xtrain,y=xtrain,epochs=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda2/lib/python2.7/site-packages/sklearn/neighbors/approximate.py:258: DeprecationWarning: LSHForest has poor performance and has been deprecated in 0.19. It will be removed in version 0.21.\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "codes=encoder.predict(xtrain)\n",
    "\n",
    "from sklearn.neighbors import LSHForest\n",
    "lshf = LSHForest(n_estimators=50).fit(codes)\n",
    "\n",
    "\n",
    "def get_similar(image, n_neighbors=2):\n",
    "\n",
    "            \n",
    "    code = encoder.predict(image[None])\n",
    "    \n",
    "    (distances,),(idx,) = lshf.kneighbors(code,n_neighbors=n_neighbors)\n",
    "    \n",
    "    return distances,xtrain[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.1920929e-07, 2.3841858e-07], dtype=float32)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_similar(xtrain[0])[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
